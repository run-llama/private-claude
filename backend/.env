# AWS Bedrock profile name
# AWS_PROFILE_NAME=

# The name of LLM model to use.
MODEL=amazon.titan-text-express-v1

# The OpenAI API key to use.
# OPENAI_API_KEY=

# The address to start the backend app.
APP_HOST=0.0.0.0

# The port to start the backend app.
APP_PORT=8000

# Name of the embedding model to use.
EMBEDDING_MODEL="BAAI/bge-small-en-v1.5"

# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=

# The number of similar embeddings to return when retrieving documents.
TOP_K=3

# Custom system prompt.
# Example:
# SYSTEM_PROMPT="
# We have provided context information below.
# ---------------------
# {context_str}
# ---------------------
# Given this information, please answer the question: {query_str}
# "
# SYSTEM_PROMPT=
